# Custom Model Registration Configuration
# ========================================
# 
# This file defines custom/internal models that are not directly
# supported by LiteLLM. These are typically:
# - Self-hosted models
# - Internal API proxies
# - Custom deployments
#
# After loading this config, you can use these models like:
#   agent = Agent(model="openai/deepseek-v3-1-terminus")
#   agent = Agent(model="openai/gpt-5")
#   agent = Agent(model="openai/claude-sonnet-4@20250514")
#
# 注意：model 格式为 "{provider}/{name}"
# api_key 和 api_base 会自动从此配置中读取，无需在 agent/user 配置中重复指定

models:
  # Internal DeepSeek deployment
  deepseek-v3-1-terminus:
    provider: openai
    api_base: http://10.11.154.46:8101/v1
    api_key: sk-E52xv6TgTOTF0UuntU9p26duAmklfL6rehw0WvHIDQQtsVGh  # Use env var or hardcode
    mode: chat

  gpt-5:
    provider: openai
    api_base: http://10.11.154.46:8101/v1
    api_key: sk-E52xv6TgTOTF0UuntU9p26duAmklfL6rehw0WvHIDQQtsVGh  # Use env var or hardcode
    mode: chat

  claude-sonnet-4@20250514:
    provider: openai
    api_base: http://10.11.154.46:8101/v1
    api_key: sk-E52xv6TgTOTF0UuntU9p26duAmklfL6rehw0WvHIDQQtsVGh  # Use env var or hardcode
    mode: chat

  deepseek-v3.2-fc:
    provider: openai
    api_base: http://api.dbh.baidu-int.com/v1
    api_key: sk-E52xv6TgTOTF0UuntU9p26duAmklfL6rehw0WvHIDQQtsVGh  # Use env var or hardcode
    mode: chat

  deepseek-v3-2-251201:
    provider: openai
    api_base: http://api.dbh.baidu-int.com/v1
    api_key: sk-E52xv6TgTOTF0UuntU9p26duAmklfL6rehw0WvHIDQQtsVGh  # Use env var or hardcode
    mode: chat